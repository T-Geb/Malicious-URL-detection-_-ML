{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "2a4c8e32-2717-44ea-bdf9-f695716f7b50"
   },
   "source": [
    "# Malicious URL Detection Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "a32ef8f6-2edf-470b-bb23-7a9717cb7578"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "-wHyMXFl6oAi"
   },
   "outputs": [],
   "source": [
    "!pip install tldextract ipywidgets > /dev/null #For URL parsing  & User Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "9ab49a17-dd84-4d25-985c-ba57b3789f71"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standard Libraries:\n",
    "import re # To handle regular expressions\n",
    "import numpy as np # Numerical operations\n",
    "import pandas as pd  # For working with DataFrame\n",
    "import ipaddress # to check ip address for feature extraction\n",
    "\n",
    "# Visualization tools:\n",
    "import matplotlib.pyplot as plt   # For Plotting\n",
    "\n",
    "# URL Parsing:\n",
    "import tldextract #For extracting domain and suffix from URLs\n",
    "\n",
    "# import matplotlib ---delete if not needed\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn import preprocessing  #To label encode y(dependent variable)\n",
    "from sklearn.model_selection import train_test_split  #To split data into train and test sets\n",
    "from sklearn.preprocessing import StandardScaler # For scaling features when needed(e.g Logistic Regression)\n",
    "\n",
    "# Machine Learning Models for Training:\n",
    "from sklearn.ensemble import RandomForestClassifier   # Model 1\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier # Model 2\n",
    "from sklearn.linear_model import LogisticRegression # Model 3\n",
    "\n",
    "# Metric for measuring model performance\n",
    "from sklearn.metrics import (\n",
    "accuracy_score,\n",
    "confusion_matrix,\n",
    "precision_score,\n",
    "recall_score,\n",
    "ConfusionMatrixDisplay,\n",
    "classification_report)\n",
    "\n",
    "# Model Comparison Tool:\n",
    "import seaborn as sns\n",
    "\n",
    "#User Interface\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output,HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "b10e24b6-718f-4fb4-b6d2-77d7d3943fd8"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "1bf9c524-af06-47ec-80d7-905de7490ad7"
   },
   "source": [
    "### Importing Dataset\n",
    "This project uses a public malicous URL dataset from Kaggle. This dataset can be found using the following link: https://www.kaggle.com/datasets/sid321axn/malicious-urls-dataset\n",
    "\n",
    "According to a discussion on Kaggle, the last 96,018 URLs that were sourced from PhishStorm might have had their labels flipped during the making of the original Kaggle set. The benign URLs were marked as phishing and phishing URLs as benign. To fix this issue, I initially tried to correct the wrong labels. However, I eventually decided to drop those URLs that were sourced from PhishStorm. This was done using command-line tools to keep only the first 555173 rows, including the header. This ensures that the corrupted labels do not affect the model's performance.\n",
    "\n",
    "The trimmed version is accessed from my repository on GitHub: https://raw.githubusercontent.com/T-Geb/Malicious-URL-detection-_-ML/main/trimmed_dataset.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "4ff755ee-1aa0-4da2-a70a-24f1134d355d"
   },
   "outputs": [],
   "source": [
    "\n",
    "mal_ds = pd.read_csv(\"https://raw.githubusercontent.com/T-Geb/Malicious-URL-detection-_-ML/main/trimmed_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "u1Y2-5ghTFq9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Verification of Proper Data Import\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "ed82b634-2577-47eb-ad99-160d167aadfc"
   },
   "source": [
    "To verify that the dataset was imported properly, the first five URLs and their corresponding labels are printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6da6268-27da-4fa2-a3e2-52f178e57302",
    "outputId": "3d31442e-e92f-499f-e15e-c36835a2d9b0"
   },
   "outputs": [],
   "source": [
    "print(mal_ds['url'][:5])\n",
    "print(mal_ds['type'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "48de63f3-ac2a-49e5-9c88-691dd76f19ff"
   },
   "source": [
    "### Deleting Rows for Duplicated URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeBreJDwGCxx",
    "outputId": "407575c5-80af-4184-ce4b-311f6852d520"
   },
   "outputs": [],
   "source": [
    "# Checking for duplicated rows in column 1 - URL list\n",
    "duplicate_urls = mal_ds[mal_ds.duplicated(subset=mal_ds.columns[0])]\n",
    "total_duplicates = duplicate_urls.shape[0]\n",
    "print(\"\\n Total row count before duplicate clean-up:\\n\", mal_ds.shape[0])\n",
    "print(\"\\nTotal number of duplicate URLs:\", total_duplicates)\n",
    "\n",
    "print(\"\\nClass distribution of duplicated URLs:\\n\")\n",
    "print(duplicate_urls['type'].value_counts())\n",
    "\n",
    "# Deleting Duplicated rows based on identified duplicates of the first column - URLs\n",
    "print(\"\\nDeleting duplicate rows....\\n\")\n",
    "mal_ds = mal_ds.drop_duplicates(subset=mal_ds.columns[0], keep='first')\n",
    "\n",
    "#Checking the number of URLs before and after dropping duplicate URLs\n",
    "print(\"\\nTotal row count after duplicate clean-up:\\n\", mal_ds.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "lyb8RO93Rqqz"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The above output shows that there are 10,064 duplicate URLs identified. To ensure consistent data and to prevent data leakage during the split into training and testing sets, these duplicates were dropped, and only the first occurrence of these URLs was retained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "a134b87d-36bf-40df-9b6b-03c2c029317f"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Checking for Missing Data\n",
    "A check is performed to verify that there is no missing data in both the url and type columns.\n",
    "\n",
    "A return value of 0 for both indicates that no missing data is found.\n",
    "\n",
    "If any missing values were found, the dropna() method ensures that these rows are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njeWTKRVBS6X",
    "outputId": "06606233-63f6-479c-fa12-9a6e73bb183f"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Checking for missing values\n",
    "count_missing_values = mal_ds.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(count_missing_values)\n",
    "\n",
    "#Drop any rows with any missing values\n",
    "mal_ds = mal_ds.dropna()\n",
    "\n",
    "# Verifying no missing values remain\n",
    "print(f\"\\nAfter cleaning missing values: {mal_ds.isnull().sum().sum()}\")\n",
    "print(f\"Final dataset size: {mal_ds.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "70fcbe06-ec67-42b3-b003-308fb922a67a"
   },
   "source": [
    "### Bar Chart Visualization: Showing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "a748824c-6211-4020-84dc-a138c856baa3",
    "outputId": "736121e6-8141-4386-f6f1-e7db7fefe210"
   },
   "outputs": [],
   "source": [
    "# Y represents - mal_ds['type']\n",
    "\n",
    "label_counts = mal_ds['type'].value_counts() #counting the values of each class using value_count. This will return a series\n",
    "total_count = sum(label_counts) # counting the type count\n",
    "\n",
    "bar_class = ['benign', 'defacement', 'malware', 'phishing']\n",
    "bar_counts = [label_counts.get(label,0) for label in bar_class]\n",
    "\n",
    "bar_colors = ['tab:red', 'tab:blue', 'tab:orange', 'tab:cyan']\n",
    "\n",
    "figure, axis = plt.subplots() #assigning figure and axis for the bar plot\n",
    "\n",
    "#Setting the x and y axis, applying color and title\n",
    "axis.bar(bar_class, bar_counts, color=bar_colors)\n",
    "\n",
    "axis.set_ylabel('Class Occurance')\n",
    "axis.set_xlabel('Classification')\n",
    "axis.set_title('Malicious Classification')\n",
    "\n",
    "\n",
    "#using a for loop to show the count in numbers on each bar\n",
    "for i, count in enumerate(bar_counts):\n",
    "  percentage = (count / total_count) * 100\n",
    "  axis.text(i, count, f'{count} ({percentage:.2f}%)', ha='center', va='bottom')\n",
    "\n",
    "print(\"\\n\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "011447c6-7cd0-4a56-bb38-c0195db47247"
   },
   "source": [
    "The bar chart above shows the original dataset's class distribution after trimming the wrong labels. It shows a significant class imbalance, with benign URLs dominating with a higher percentage of 69.74 and malware URLs showing the lowest percentage of 4.34.\n",
    "\n",
    "This could impact machine learning models as it leads to bias towards the majority class, impacting the detection of malicious URLs, such as defacement, malware, and phishing.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "GEdqfGc8GQAF"
   },
   "source": [
    "## Balancing Classifications\n",
    "\n",
    "To ensure the model is not biased towards benign URLs and minority classes(defacement, phishing, and malware) detection is maintained, and I have decided to use random sampling to get 23,000 URLs from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fCmOUS4GQ0J",
    "outputId": "d0cee4f0-5930-4530-b9c7-cde5966525cc"
   },
   "outputs": [],
   "source": [
    "# sample(n=23000) takes 23,000 random rows\n",
    "\n",
    "benign = mal_ds[mal_ds['type'] == 'benign'].sample(n=23000)\n",
    "defacement = mal_ds[mal_ds['type'] == 'defacement'].sample(n=23000)\n",
    "phishing = mal_ds[mal_ds['type'] == 'phishing'].sample(n=23000)\n",
    "malware = mal_ds[mal_ds['type'] == 'malware'].sample(n=23000)\n",
    "\n",
    "balanced_df = pd.concat([benign, defacement, phishing, malware])\n",
    "\n",
    "X = balanced_df.iloc[:,0]  #getting all rows from the first column - urls: the independent variable\n",
    "Y = balanced_df.iloc[:,1] # getting all rows from the second column - types : the dependent variable\n",
    "\n",
    "print(\"Total Sample Size:\",balanced_df.shape[0])\n",
    "print(\"\\nSamples per type:\")\n",
    "print(balanced_df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "4063ac30-b51f-4724-a40d-68f272cdc8ed"
   },
   "source": [
    "### Label Encoding - Dependent Variable, Y - Classifications\n",
    "\n",
    "Since the labels(classes) are strings[benign, defacement, malware, phishing], they need to be converted into numeric values so the machine learning models can process them. I am using label encoding to assign a unique integer to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac252c60-8494-405e-b4e2-e07f53d15dbe",
    "outputId": "0b1458b8-c36b-468c-fd2f-e535057aa600"
   },
   "outputs": [],
   "source": [
    "# Y represents - balanced_df['type']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)  # Assigning labels to numbers\n",
    "\n",
    "#le.classes_ - stores the internal mapping\n",
    "# le.transform - This maps the labels to the assigned values\n",
    "\n",
    "numeric_value = le.transform(le.classes_)\n",
    "class_label = le.classes_\n",
    "\n",
    "print(\"\\nShowing Label Mapping:\\n\")\n",
    "for i in range(len(numeric_value)):\n",
    "    print(f\"{class_label[i]}: {numeric_value[i]}\")\n",
    "\n",
    "\n",
    "y = le.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "329b8215-bf25-4367-8df6-aaf97de9de79"
   },
   "source": [
    "### Bar Chart of Top 4 Domain-Suffixes in Dataset\n",
    "\n",
    "This visualization displays the four most common domain suffixes in the dataset. Identifying frequently used suffixes helps see trends that could be used for feature extraction.\n",
    "\n",
    "I am using the tldextract library to handle domain extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "b663b1c0-47d6-40eb-847c-d8baa25816ee"
   },
   "outputs": [],
   "source": [
    "extractor = tldextract.TLDExtract(cache_dir=False) # disabling network access to avoid issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "6ec1b7fc-3e40-41d5-b6e6-63f4eb303cf1",
    "outputId": "63a5b957-803c-412d-aa5a-beecca272bb4"
   },
   "outputs": [],
   "source": [
    "# X represents - balanced_df['urls']\n",
    "#creating a method to work on one URL at a time to extract the suffix, and applying the method to the URLs column\n",
    "# This method will also be used later on for feature extraction\n",
    "\n",
    "def get_suffix(url):\n",
    "    return tldextract.extract(url).suffix.lower()\n",
    "\n",
    "extd_domains = X.apply(get_suffix)\n",
    "top_domains = extd_domains.value_counts().head(4)\n",
    "total_count = top_domains.sum()\n",
    "suffix_name = top_domains.index.tolist()\n",
    "suffix_counts= top_domains.values\n",
    "bar_colors = ['tab:red', 'tab:blue', 'tab:orange', 'tab:cyan']\n",
    "\n",
    "#plotting the histogram\n",
    "figure, axis = plt.subplots()\n",
    "\n",
    "print(\"Showing the four top domains\\n\\n\" , top_domains)\n",
    "axis.bar(suffix_name, suffix_counts,color=bar_colors)\n",
    "axis.set_ylabel('Count')\n",
    "axis.set_xlabel('Domain Suffix')\n",
    "axis.set_title('Top Four Domain-Suffix In Dataset')\n",
    "\n",
    "\n",
    "#using a for loop to show the count on each bar\n",
    "for i, count in enumerate(suffix_counts):\n",
    "  percentage = (count / total_count) * 100\n",
    "  axis.text(i, count, f'{count} ({percentage:.2f}%)', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "KMhIibOKldDC"
   },
   "source": [
    "The above chart shows that .com domains dominate the dataset. 11,599 URLs also show as having missing suffixes. It also suggests that a lot of the malicious URLs might contain .com as the domain along with the benign URLs. This indicates that the domain suffix alone is not a strong indicator for distinguishing URL types.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "ab99d3ec-6afb-4093-b41b-2b225ddaba96"
   },
   "source": [
    "### Manual Feature Engineering of URLs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "ae51d408-52eb-4a07-ae39-fc22a4b133a9"
   },
   "source": [
    "#### Feature Extraction Methods\n",
    "\n",
    "Feature extraction is used to transform the raw URLs into meaningful numeric information that the models can use. My feature extraction focuses on lexical features by analyzing the contents within the URL from different angles. These extractions give the models patterns to recognize during training.\n",
    "Since all of these methods return numeric values, no additional encoding is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "314c0cfa-80c7-4480-99ca-960f494d0283"
   },
   "outputs": [],
   "source": [
    "def get_url_length(url):\n",
    "    return len(url)\n",
    "\n",
    "def count_digits(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "def equals_count(url):\n",
    "    return url.count('=')\n",
    "\n",
    "def question_count(url):\n",
    "    return url.count('?')\n",
    "\n",
    "def hyphen_count(url):\n",
    "    return url.count('-')\n",
    "\n",
    "def count_other_special_chars(url):\n",
    "    pattern = r'[^a-zA-Z0-9=?-]'  #since equals, question mark and hyphen are counted separately, I'm excluding them in the count for special chars\n",
    "    special_char = re.findall(pattern,url)\n",
    "    count = len(special_char)\n",
    "    return count\n",
    "\n",
    "def https_check(url):\n",
    "    return 1 if url.startswith(\"https\") else 0\n",
    "\n",
    "# A method to get the full domain e.g www.123.com. This method will be used in the domain_number_check method\n",
    "def get_full_domain(url):\n",
    "    return tldextract.extract(url).fqdn\n",
    "\n",
    "\n",
    "# A method to check if the entire domain is made of numbers and dots\n",
    "# This will check if the domain is IP-like numbers, which can be an indicator of malicious intent in a URL.\n",
    "\n",
    "def count_nums_in_domain(url):\n",
    "    domain = get_full_domain(url)\n",
    "    digit_count = 0\n",
    "    for char in domain:\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "    return digit_count\n",
    "\n",
    "\n",
    "#check if the domain is an IP address\n",
    "def domain_is_ip(url):\n",
    "\n",
    "    domain = get_full_domain(url)\n",
    "    try:\n",
    "        ipaddress.ip_address(domain)\n",
    "        return 1\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def suspicious_suffix(url):\n",
    "    suffix = get_suffix(url)\n",
    "    if suffix in ('',\"info\",\"cn\",\"cc\",\"asia\",\"tk\",\"biz\",\"fm\",\"tv\",\"xyz\",\"ml\"):\n",
    "        return 1 # if the domain suffix matches one of the suffixes in this list, indicating suspcious domain\n",
    "    else:\n",
    "        return 0  # if the domain suffix doesn't match..return 0\n",
    "\n",
    "\n",
    "def count_suspicious(url):\n",
    "    keywords = [\"ebayisapi\",\"webscr\",\"rfc\",\"webmail\",\"login\",\"re2\",\"servlet\",\"urgent\",\"confirm\",\"signin\",\"login\",\"login2\",\n",
    "                \"account\",\"validate\",\"activate\",\"secure\",\"blogs\",\"crypto\",\"pay\",\"fish\"]\n",
    "    url = url.lower()\n",
    "    count = 0\n",
    "    for word in keywords:\n",
    "        if word in url:\n",
    "            count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "08446a12-6a69-411e-ac91-a5ad2c7522e9"
   },
   "source": [
    "#### Testing Functionality of Feature Methods\n",
    "\n",
    "A few test URLs were plugged into the methods to show that the methods return the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe2286eb-9db1-4c64-80a6-ee515950b304",
    "outputId": "d5bb5576-2851-4ef6-b4b6-b3bb407dc745"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_urls = [\n",
    "    \"https://www.google.com\",\n",
    "    \"https://www.alsothecrumbsplease.com/authentic-black-forest-cake\",\n",
    "    \"http://sample.info/?drain=mine&direction=lock#cable\",\n",
    "    \"http://bank-confirm.com/login\",\n",
    "    \"https://www.sample.edu/?query.8\"\n",
    "]\n",
    "\n",
    "for url in test_urls:\n",
    "    print(f\"URL: {url}\")\n",
    "    print(\"URL Length:\", get_url_length(url))\n",
    "    print(\"Digit Count:\", count_digits(url))\n",
    "    print(\"Special char count:\", count_other_special_chars(url))\n",
    "    print(\"Equals sign count:\", equals_count(url))\n",
    "    print(\"Question mark count:\", question_count(url))\n",
    "    print(\"Hyphen count:\", hyphen_count(url))\n",
    "    print(\"Suspicious keyword count:\", count_suspicious(url))\n",
    "    print(\"get_domin:\", get_full_domain(url))\n",
    "    print(\"Domain is IP?:\", domain_is_ip(url))\n",
    "    print(\"is domain number:\", count_nums_in_domain(url))\n",
    "    print(\"Domain Suffix: \", get_suffix(url)) #nothing being returned\n",
    "    print(\"Suspicious suffix :\", suspicious_suffix(url))\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "79175cac-3d1a-4645-8565-8a5ef1b51423"
   },
   "source": [
    "### Splitting Data into Train and Test Set\n",
    "\n",
    "The training set will have 80% of the data, and the test set will have 20%. With 92,000 records available, 20% should be sufficient for testing.\n",
    "I used 'random_state = 42' to ensure that the same random split is applied each time the program is run, and stratify=y to keep class balance during split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "7a591597-2456-40d2-b34a-a20db20dc6ff"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "48c0ac10-6829-4cca-b162-52df9d4289b1"
   },
   "source": [
    "#### Verification of balanced class split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eee78d05-84c0-4d90-9323-60472963332e",
    "outputId": "638ebccf-8c6a-444d-8b5d-5be8e8e4707a"
   },
   "outputs": [],
   "source": [
    "label_mapping = {0: 'Benign', 1: 'Defacement', 2: 'Malware', 3: 'Phishing'}\n",
    "\n",
    "print(\"\\nTrain set class distribution:\\n\")\n",
    "print(pd.Series(y_train).value_counts().sort_index().rename(index=(label_mapping)).to_string())\n",
    "\n",
    "print(\"\\n\\nTest set class distribution:\\n\")\n",
    "print(pd.Series(y_test).value_counts().sort_index().rename(index=(label_mapping)).to_string())\n",
    "\n",
    "print(\"\\nTotal rows in train set:\", len(x_train))\n",
    "print(\"Total rows in test set:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "_kZHEyY7qwXX"
   },
   "source": [
    "The above output shows that class balance is maintained within the training and testing sets.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "f474f602-e62a-4ec6-bf3b-2c8512b2aee7"
   },
   "source": [
    "\n",
    "### Applying Features to Train and Test Set Dataframes\n",
    "\n",
    "For this specific program, the feature extraction methods need to be applied to both the x_train and x_test sets because the model needs these numeric trends to make predictions. This does not cause data leakage, as the feature extractions operate on rows and no statistical generation was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "666e02ef-0227-4bbe-9fca-81ffa02dab0a",
    "outputId": "9d1abe86-4770-40a2-c14a-e8531e95d30e"
   },
   "outputs": [],
   "source": [
    "#creating a data frame for x_train and x_test and adding the feature extractions as columns in the dataframe\n",
    "# Used the pandas library to create the dataframes and apply the methods.\n",
    "\n",
    "x_train_df = pd.DataFrame({\n",
    "    'url_length': x_train.apply(get_url_length),\n",
    "    'digit_counts': x_train.apply(count_digits),\n",
    "    'equals_count' : x_train.apply(equals_count),\n",
    "    'question_count' : x_train.apply(question_count),\n",
    "    'hyphen_count' : x_train.apply(hyphen_count),\n",
    "    'count_special_chars' : x_train.apply(count_other_special_chars),\n",
    "    'https_check' : x_train.apply(https_check),\n",
    "    'count_nums_in_domain' : x_train.apply(count_nums_in_domain),\n",
    "    'domain_is_ip' : x_train.apply(domain_is_ip),\n",
    "    'suspicious_suffix' : x_train.apply(suspicious_suffix),\n",
    "    'count_suspicious' : x_train.apply(count_suspicious)\n",
    "})\n",
    "\n",
    "x_test_df = pd.DataFrame({\n",
    "    'url_length' : x_test.apply(get_url_length),\n",
    "    'digit_counts' : x_test.apply(count_digits),\n",
    "    'equals_count' : x_test.apply(equals_count),\n",
    "    'question_count' : x_test.apply(question_count),\n",
    "    'hyphen_count' : x_test.apply(hyphen_count),\n",
    "    'count_special_chars' :x_test.apply(count_other_special_chars),\n",
    "    'https_check' : x_test.apply(https_check),\n",
    "    'count_nums_in_domain' : x_test.apply(count_nums_in_domain),\n",
    "    'domain_is_ip' : x_test.apply(domain_is_ip),\n",
    "    'suspicious_suffix' : x_test.apply(suspicious_suffix),\n",
    "    'count_suspicious' : x_test.apply(count_suspicious)\n",
    "})\n",
    "\n",
    "print(\"\\nFirst 5 rows of the extracted features for x_train \\n\")\n",
    "display(x_train_df.head(5))\n",
    "\n",
    "print(\"\\n\\nFirst 5 rows of the extracted features for x_test \\n\")\n",
    "display(x_test_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "02fa8819-e275-4226-ac34-086d41581f97"
   },
   "source": [
    "## Model Training, Test and Evaluation\n",
    "\n",
    "Model training for this project is done on 3 models. These models are as follows:\n",
    "1. Logistic Regression\n",
    "2. Hist Gradient Boosting Classifier\n",
    "3. Random Forest Classifier\n",
    "\n",
    "The evaluation will look at accuracy and f1-scores as metrics to evaluate the performance of models. f1-score gives a single number by combining both precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "id": "181a4c22-f78f-4606-bf05-cfec531f5ae2"
   },
   "source": [
    "### Model 1 : Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "08cd44b4-03ae-4abf-8f2f-fe94c252ead7"
   },
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "id": "9baf0be5-f9e1-423b-9f2a-8e1fd4acbd24",
    "outputId": "350e92ca-217b-412c-9354-6678c32b67cb"
   },
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state = 42)\n",
    "\n",
    "#scaling features to treat features equally with logistic regression\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_df)\n",
    "x_test_scaled = scaler.transform(x_test_df)\n",
    "print(type(x_train_scaled))\n",
    "\n",
    "log_model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "21baa2dd-138f-4198-8213-b1b90e27bcb0"
   },
   "source": [
    "#### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "id": "30864fdf-7a19-4003-bf7a-a3991fb3dbb6"
   },
   "outputs": [],
   "source": [
    "y_pred_log=log_model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "id": "fe767d8e-37b0-4c7a-a086-49bf9d691314"
   },
   "source": [
    "#### Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "7d767194-cd55-4ea2-be72-b89926fcb2f6",
    "outputId": "20a353c1-4909-4fae-c3b9-298f4abc61aa"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred_log)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Showing classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "report_log_str = classification_report(y_test,y_pred_log,target_names=le.classes_)  # for printing\n",
    "report_log_dict = classification_report(y_test,y_pred_log,output_dict=True) # for heatmap - model comparision\n",
    "\n",
    "print(report_log_str)\n",
    "\n",
    "#Plotting a confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log, display_labels=le.classes_,cmap=\"Blues\", normalize=\"true\")\n",
    "plt.title(\"Confusion Matrix for Model 3 - Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "TfB3kl9uzwVi"
   },
   "source": [
    "**Evaluation Summary: Logistic Regression**\n",
    "\n",
    "This model performed the weakest overall, with an overall accuracy of 66% and a low F1-score of 0.45 for phishing. This shows that logistic regression may not be the best choice for a dataset with complex features\n",
    "\n",
    "-- Results may vary slightly during reruns due to model randomness.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "id": "f5ffb8f6-c57f-4181-9eee-af21b97d6ea9"
   },
   "source": [
    "### Model 2 : Hist Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "c653db43-2f0e-47e6-b0e6-4d98f75b0cf6"
   },
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "3a149188-2a56-4e9d-9af1-465aa44594a8",
    "outputId": "cc5b9e92-dd97-43a9-a883-c6cb65574d33"
   },
   "outputs": [],
   "source": [
    "hist_gbc= HistGradientBoostingClassifier(random_state = 42)\n",
    "hist_gbc.fit(x_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "id": "dcd2878c-98e9-4c7b-a8f6-8be472ec7f23"
   },
   "source": [
    "#### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "id": "9f613741-4215-4de3-ba99-10f3c02a8b6a"
   },
   "outputs": [],
   "source": [
    "y_pred_hist=hist_gbc.predict(x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "cbbf4642-6772-431e-9bad-c62618464ef2"
   },
   "source": [
    "#### Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "fcf6c841-f7aa-4a52-b11a-f7577522a3e1",
    "outputId": "b0e539df-dc9f-4dc2-ec64-0bc5f929ac62"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred_hist)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Showing classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "report_hist_str = classification_report(y_test,y_pred_hist,target_names=le.classes_) # for printing\n",
    "report_hist_dict = classification_report(y_test,y_pred_hist,output_dict=True) # for heatmap - model comparision\n",
    "print(report_hist_str)\n",
    "\n",
    "#Plotting a confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_hist, display_labels=le.classes_,cmap=\"Blues\", normalize=\"true\")\n",
    "plt.title(\"Confusion Matrix for Model 2 - Hist Gradient Boosting Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "RzaHLNYzy_3e"
   },
   "source": [
    "**Evaluation Summary: Hist Gradient Boosting Classifier**\n",
    "\n",
    "- The model achieved an accuracy of 86%\n",
    "- Malware here shows the highest F1-score(0.91), showing strong detection ability.\n",
    "- Phishing shows the lowest F1-score(0.82), which shows the model can, at times, struggle to identify phishing URLs. This is to be expected, as most phishing URLs present themselves as safe and rely on social engineering\n",
    "\n",
    "\n",
    "-- Results may vary slightly during reruns due to model randomness.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "ba62bffa-62f7-4bb4-8d3a-12fcf0d6d8d2"
   },
   "source": [
    "### Model 3 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {
    "id": "faa15ab6-b578-4897-864c-ac7152294f42"
   },
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "147b2dc2-318f-4e35-8415-84d16a3b389c",
    "outputId": "72331761-1ebd-492b-f5a9-b68b5eefe9b2"
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state = 42)\n",
    "random_forest.fit(x_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {
    "id": "55a511bb-3d45-4080-b032-ee6ac431e831"
   },
   "source": [
    "#### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "id": "9c205269-5b9b-4150-b24b-97221a0ebc33"
   },
   "outputs": [],
   "source": [
    "y_pred_rf = random_forest.predict(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "845d73f6-cbd3-4973-87a9-e1c91cabd402",
    "outputId": "3581a942-51bb-4df6-8793-0965c348ba06"
   },
   "outputs": [],
   "source": [
    "# Model accuracy measurement\n",
    "accuracy = accuracy_score(y_test,y_pred_rf)\n",
    "print(f\"Model Accurancy: {accuracy:.2f}\")\n",
    "\n",
    "# Showing classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "report_rf_str = classification_report(y_test,y_pred_rf,target_names=le.classes_) # for printing report\n",
    "report_rf_dict = classification_report(y_test,y_pred_rf,output_dict=True) # for heatmap - model comparision\n",
    "\n",
    "print(report_rf_str)\n",
    "# Plotting a confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf, display_labels=le.classes_,cmap=\"Blues\", normalize=\"true\")\n",
    "plt.title(\"Confusion Matrix for Model 1 - Random Forest Classifier\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "id": "f23c17c5-999d-4052-aabe-b1c2149c7bcb"
   },
   "source": [
    "#### Evaluating Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {
    "id": "wrCcfSUz58dr"
   },
   "source": [
    "**Evaluation Summary: Random Forest Classifier**\n",
    "- The model achieved an accuracy of 86% at the time of run\n",
    "- Malware had the highest F1-score(0.91), showing the model can identify malware URLs better than other classes.\n",
    "- Phishing again had the lowest F1-score(0.82), which was heavily influenced by its low recall. This indicates that the detection of phishing remains harder\n",
    "\n",
    "-- Results may vary slightly during reruns due to model randomness.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "id": "pQ5U0dRVnlRF"
   },
   "source": [
    "## Model Comparison and Selection Model for User Interaction\n",
    "\n",
    "I have trained, tested, and evaluated three models. The classification reports and confusion matrices show individual reports for each model. To visually compare the performance of the three models, I am creating a heatmap by using the F1-score of each class in each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "XrfJKHiUojYQ",
    "outputId": "4c590cfc-76e5-4534-8c12-ff7f8ac50705"
   },
   "outputs": [],
   "source": [
    "\n",
    "# putting the model name and the dict classfication report in a dictionary\n",
    "model_predictions = {\n",
    "    \"Random Forest\": report_rf_dict,\n",
    "    \"Hist Gradient Boosting\": report_hist_dict,\n",
    "    \"Logistic Regression\": report_log_dict\n",
    "}\n",
    "\n",
    "class_labels = [\"Benign\", \"Defacement\", \"Malware\",\"Phishing\"]\n",
    "class_keys = ['0','1','2','3']\n",
    "\n",
    "f1_data = {} # creating an empty dictionary to put the model name along with the list of f1-scores for each class\n",
    "\n",
    "\n",
    "# a for loop to parse through the model_prediction dictionary and extract the F1-score for each class from each model's classification report.\n",
    "for model_name, report in model_predictions.items():\n",
    "  f1_scores = []\n",
    "  for class_key in class_keys:\n",
    "    f1 = report[class_key]['f1-score']\n",
    "    f1_scores.append(f1)\n",
    "  f1_data[model_name] = f1_scores\n",
    "\n",
    "\n",
    "# plotting heatmap\n",
    "f1_dataframe = pd.DataFrame(f1_data, index=class_labels).T\n",
    "sns.heatmap(f1_dataframe,annot=True,fmt=\".2f\")\n",
    "plt.title(\"F1 Score Comparision Across Models and Classes\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Models\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {
    "id": "NUu3WbMP9L5C"
   },
   "source": [
    "## Model Selection\n",
    "\n",
    "Based on the accuracy metric, classification reports, and heat map visualization, the final model is trained using the **Random Forest Classifier**. This model shows a higher F1-score compared to the other models. This indicates that precision and recall were fairly high. Phishing URL f1-score shows the lowest performance.\n",
    "\n",
    "The model trained using Logistic Regression did not perform as well as the other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {
    "id": "dEQiunbNrwsi"
   },
   "source": [
    "## Generating Sample URLs\n",
    "Generating URLs from the test set to provide the user with sample input. Since these are pulled from the test set, the model has not yet learned them and can be used as a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "id": "DnkTGg8TupWp"
   },
   "outputs": [],
   "source": [
    "sample_urls = x_test.sample(10,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {
    "id": "c5db5be2-5318-4157-89d9-dc0c12dd81e7"
   },
   "source": [
    "\n",
    "## User Interface - URL Safety Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425,
     "referenced_widgets": [
      "9bc4879b7e6e444981b7f7794e5e8fe9",
      "2ad1b65a00e54a7b89b8b35cccb14a92",
      "faf947274e334fc5a48bf4f7d957e366",
      "f2a2559d8a0541e48adb5ebf5b9cdd0d",
      "d4cbb2575be64ea5a34dcd2ba28c8f9b",
      "f05322e495714e1cb967d1e81afd7458",
      "f4e3662e93114d09b0c8061c30ed6d5d",
      "73d303a3ee83412d8784cc3ea613d885",
      "305b221eedd641bfa9c67ced9bdb5346",
      "aa2c618882784250ab96a062f7ea458f",
      "5e8b167df3024871b12bf6de50a50483",
      "f8f731a7335c4825a225e088d48be114",
      "13fbbab55c1848fca2c094f7245c25a4",
      "423319056f5245f49121d82029dec78e",
      "dc316deee42c4a059635675c247fe00c",
      "c6848addcbd64c9fb87e64da0c9357cf",
      "68ba594c0a4542829e7398f7d27a1848",
      "e46012430200471abaf6c98ef18abcfd"
     ]
    },
    "id": "a1132394-52d2-4205-b556-8b64225e3090",
    "outputId": "1318de23-57f9-41d1-d7b5-71e37d4424a1"
   },
   "outputs": [],
   "source": [
    "## URL Check: User Interaction\n",
    "\n",
    "\n",
    "def run_url_checker():\n",
    "  print(\"\\nEnter a URL from the sample list or input your own, then click submit\\n \\nOr --  Type 'q' and click submit to exit interface.\\n\")\n",
    "\n",
    "# Sampling 10 URLs from the x_test set to provide to user\n",
    "\n",
    "  sample_options = [\"Select a sample URL....\"] + sample_urls.values.tolist()\n",
    "\n",
    "  dropdown = widgets.Dropdown(options=sample_options, description=\"Samples:\")\n",
    "\n",
    "\n",
    "  text_box = widgets.Text(placeholder = \"Enter url and press Enter on keyboard\")\n",
    "  submit_button = widgets.Button(description=\"Submit\",button_style='Primary')\n",
    "\n",
    "# to fill the text box when dropdown changes\n",
    "  def on_dropdown_change(change):\n",
    "    if change.new != \"Select a sample URL....\":\n",
    "      text_box.value = change.new\n",
    "\n",
    "  dropdown.observe(on_dropdown_change, names='value')\n",
    "  display(dropdown)\n",
    "  display(HTML(\"<br>\"))\n",
    "  display(text_box,)\n",
    "  display(HTML(\"<br>\"))\n",
    "  display(submit_button)\n",
    "  display(HTML(\"<br>\"))\n",
    "\n",
    "  def submit(sender=None):\n",
    "    url = text_box.value.strip()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "\n",
    "    if not url:\n",
    "        print(\"Please enter a URL.\")\n",
    "        return\n",
    "    elif url == 'q':\n",
    "        print(\"\\n\\nProgram Exited.\")\n",
    "        return\n",
    "\n",
    "    text_box.value = \"\" # prepare for next input\n",
    "\n",
    "    extracted_features = pd.DataFrame([{\n",
    "        'url_length': get_url_length(url),\n",
    "        'digit_counts': count_digits(url),\n",
    "        'equals_count' : equals_count(url),\n",
    "        'question_count' : question_count(url),\n",
    "        'hyphen_count' : hyphen_count(url),\n",
    "        'count_special_chars' : count_other_special_chars(url),\n",
    "        'https_check' : https_check(url),\n",
    "        'count_nums_in_domain' : count_nums_in_domain(url),\n",
    "        'domain_is_ip' : domain_is_ip(url),\n",
    "        'suspicious_suffix' : suspicious_suffix(url),\n",
    "        'count_suspicious' : count_suspicious(url)\n",
    "    }])\n",
    "\n",
    "    prediction = random_forest.predict(extracted_features)[0]\n",
    "    print(\"\\n\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>URL Safety Prediction>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\n\\n\")\n",
    "    display(HTML(f\"URL Entered: {url}\\n\"))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if prediction == 0:\n",
    "      display(HTML(f\"<b> Prediction: <span style='color:green;'>Benign - Safe</span></b><br><br>\"))\n",
    "\n",
    "    elif prediction == 1:\n",
    "      display(HTML(f\"<b> Prediction: <span style='color:red;'>Malicious - Possible Defacement</span></b><br><br>\"))\n",
    "\n",
    "    elif prediction == 2:\n",
    "      display(HTML(f\"<b> Prediction: <span style='color:red;'>Malicious - Possible Malware</span></b><br><br>\"))\n",
    "\n",
    "    elif prediction == 3:\n",
    "      display(HTML(f\"<b> Prediction: </b> <span style='color:red;'>Malicious - Possible Phishing</span></b><br><br>\"))\n",
    "\n",
    "    run_url_checker() # show input form for another entry\n",
    "\n",
    "\n",
    "  text_box.on_submit(submit)\n",
    "  submit_button.on_click(submit)\n",
    "\n",
    "run_url_checker()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
